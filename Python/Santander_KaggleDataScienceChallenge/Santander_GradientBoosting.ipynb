{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier,ExtraTreesRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading input train and test data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "# removing the constant columns\n",
    "remove = []\n",
    "for col in train.columns:\n",
    "    if train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "        \n",
    "train.drop(remove, axis=1, inplace=True)\n",
    "test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "train.drop(remove, axis=1, inplace=True)\n",
    "test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "target = train['TARGET'].values\n",
    "train = train.drop(['ID','TARGET'], axis=1)\n",
    "\n",
    "id_test = test['ID'].values\n",
    "test = test.drop(['ID'], axis=1)\n",
    "\n",
    "# length of dataset\n",
    "len_train = len(train)\n",
    "len_test  = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "len(train.columns)\n",
    "\n",
    "# Functions,code for feature engineering\n",
    "\n",
    "def getCounts(x):\n",
    "    count=0\n",
    "    for i in x:\n",
    "        if i==0:\n",
    "            count=count+1\n",
    "    return count\n",
    "#sum of zeros across the instances\n",
    "train['zeroCounts']=train.apply(getCounts,axis=1)\n",
    "test['zeroCounts']=test.apply(getCounts,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a GBT classifier \n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "gbt= GradientBoostingClassifier(learning_rate=0.01, subsample=0.8, max_depth=5,max_features=250,n_estimators=160,\n",
    "                                random_state=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checking the cross validation for the classifier\n",
    "scores=cross_validation.cross_val_score(gbt,train,target,cv=5,scoring='roc_auc')\n",
    "print scores\n",
    "print(\"Accuracy: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.3320           0.0016            3.57m\n",
      "         2           0.3308           0.0015            3.58m\n",
      "         3           0.3278           0.0015            3.59m\n",
      "         4           0.3241           0.0014            3.58m\n",
      "         5           0.3253           0.0013            3.57m\n",
      "         6           0.3224           0.0013            3.57m\n",
      "         7           0.3263           0.0011            3.55m\n",
      "         8           0.3195           0.0012            3.54m\n",
      "         9           0.3223           0.0012            3.53m\n",
      "        10           0.3218           0.0010            3.50m\n",
      "        20           0.3090           0.0008            3.26m\n",
      "        30           0.3007           0.0006            3.03m\n",
      "        40           0.2956           0.0005            2.79m\n",
      "        50           0.2892           0.0004            2.56m\n",
      "        60           0.2858           0.0003            2.32m\n",
      "        70           0.2834           0.0003            2.09m\n",
      "        80           0.2785           0.0002            1.87m\n",
      "        90           0.2760           0.0002            1.64m\n",
      "       100           0.2743           0.0001            1.41m\n"
     ]
    }
   ],
   "source": [
    "# Fit the classifier on the train data\n",
    "gbt.fit(train,target)\n",
    "\n",
    "\n",
    "# Predicting on the test data\n",
    "probs = gbt.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forming the submission dataframe\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\": probs[:,1]})\n",
    "submission.to_csv(\"submission_santander.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
